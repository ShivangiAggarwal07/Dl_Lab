# -*- coding: utf-8 -*-
"""Dl_Lab_Exam_(Shivangi aggarwal).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rDJbNkfO6-Gb72BYF8iTH7OjPD37n6oh
"""

import kagglehub

# Downloading the latest version
path = kagglehub.dataset_download("jonathanoheix/face-expression-recognition-dataset")

print("Path to dataset files:", path)

import os

# Defining the correct dataset path
dataset_path = "/root/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1"

# Checking the directory structure at the root level
print("Dataset contents:", os.listdir(dataset_path))

# Defining the path to the 'images' folder
images_dir = os.path.join(dataset_path, 'images')

# Checking the contents inside the 'images' folder
print("Images directory contents:", os.listdir(images_dir))

# Checking the contents of 'train' and 'validation' directories
train_dir = os.path.join(images_dir, 'train')
validation_dir = os.path.join(images_dir, 'validation')

# Also Listing the contents of both directories
print("Train directory contents:", os.listdir(train_dir))
print("Validation directory contents:", os.listdir(validation_dir))

#Importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator # ImageDataGenerator is part of tf.keras
from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.utils import load_img, img_to_array # Use tensorflow.keras.utils for load_img and img_to_array
from tensorflow.keras.layers import Dense, Input, Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam

"""###Displaying some images"""

folder_path = '/root/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/'
picture_size = (50, 50)  # 48x48 image size

# Expression to display, I will be picking angry
expression = 'angry'

# Plotting the images
plt.figure(figsize=(12, 12))
for i in range(1, 10):
    # Getting the image file path
    img_path = os.path.join(folder_path, 'train', expression, os.listdir(os.path.join(folder_path, 'train', expression))[i])

    # Loading the image and display it
    img = load_img(img_path, target_size=picture_size)
    plt.subplot(3, 3, i)
    plt.imshow(img)
    plt.axis('off')  # It will Hide axis

plt.show()

"""#Data Augmentation (To prevent overfitting)"""

# Defining image dimensions
picture_size = (48, 48)  # 48x48 image size
img_width, img_height = picture_size  # Unpack the tuple


train_set = datagen.flow_from_directory(folder_path+"train",
                                              target_size = (img_width, img_height),  # Pass width and height directly
                                              color_mode = "grayscale",
                                              batch_size=batch_size,
                                              class_mode='categorical',
                                              shuffle=True)


test_set = datagen.flow_from_directory(folder_path+"validation",
                                              target_size = (img_width, img_height),  # Pass width and height directly
                                              color_mode = "grayscale",
                                              batch_size=batch_size,
                                              class_mode='categorical',
                                              shuffle=False)

# ... (rest of your code) ...

"""#Displaying the generated data"""

plt.figure(figsize= (10,10))
for i in range(1,5,1):
    img, label = next(train_set)
    print(img.shape)
    plt.subplot(3,4,i)
    plt.imshow(img[1,:,:,0], cmap='gray') # Displaying the image with grayscale colormap
    plt.title(f"Label: {np.argmax(label[1])}") # Displaying the label of the image
plt.show()

"""#CNN Architecture"""

no_of_classes = 7

model = Sequential()

#1st CNN layer
model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout(0.25))

#2nd CNN layer
model.add(Conv2D(128,(5,5),padding = 'same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout (0.25))

#3rd CNN layer
model.add(Conv2D(512,(3,3),padding = 'same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout (0.25))

#4th CNN layer
model.add(Conv2D(512,(3,3), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())

#Fully connected 1st layer
model.add(Dense(256))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))


# Fully connected layer 2nd layer
model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))

model.add(Dense(no_of_classes, activation='softmax'))

model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])

from tensorflow.keras.utils import plot_model
from IPython.display import Image
plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)
Image('model.png',width=1000, height=3000)

model.summary()

"""#Saving Model by checkpoint"""

from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

checkpoint = ModelCheckpoint("./model.h5", monitor='val_acc', verbose=1, save_best_only=True, mode='max')

early_stopping = EarlyStopping(monitor='val_loss',
                          min_delta=0,
                          patience=3,
                          verbose=1,
                          restore_best_weights=True
                          )

reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',
                              factor=0.2,
                              patience=3,
                              verbose=1,
                              min_delta=0.0001)

callbacks_list = [early_stopping,checkpoint,reduce_learningrate]

"""
#Compiling the model"""

model.compile(loss='categorical_crossentropy',
              optimizer = Adam(learning_rate=0.001),
              metrics=['accuracy'])

"""#Training the model"""

history = model.fit(x=train_set,
                                steps_per_epoch=train_set.n//train_set.batch_size,
                                epochs=10,
                                validation_data = test_set,
                                validation_steps = test_set.n//test_set.batch_size,
                                callbacks=callbacks_list
                                )

"""Predict one value from test_set"""

img, label = test_set[11]
print(img.shape)
print(img[11].shape)

plt.imshow(img[11])

y_pred = model.predict(img)
y_pred = np.argmax(y_pred, axis=1)

# Defining class_names based on our dataset labels
class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']  # Replace with your actual class names

print(class_names[y_pred[0]])
print('class:'+ str(y_pred[0]))

"""#Display Stats"""

plt.figure(figsize=(20,10))
plt.subplot(1, 2, 1)
plt.suptitle('Optimizer : Adam', fontsize=10)
plt.ylabel('Loss', fontsize=16)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend(loc='upper right')

plt.subplot(1, 2, 2)
plt.ylabel('Accuracy', fontsize=16)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend(loc='lower right')
plt.show()

#Accuracy of the model
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
#Loss of the model
loss = history.history['loss']
val_loss = history.history['val_loss']

#printing accuracy of the model
print("Accuracy of the model is: ", acc)

## List of accuracy values from different steps
acc1= history.history['accuracy']
acc2= history.history['val_accuracy']
print(acc1)
print(acc2)

# List of accuracy values from different steps
acc1 = [0.2639319598674774, 0.3671875, 0.3679642975330353, 0.421875, 0.43805110454559326, 0.484375, 0.48001253604888916, 0.5234375, 0.5090439915657043, 0.5078125]
acc2 = [0.25980114936828613, 0.26008522510528564, 0.3205966055393219, 0.32315340638160706, 0.44815340638160706, 0.4417613744735718, 0.4934659004211426, 0.4876420497894287, 0.4474431872367859, 0.4170454442501068]

# Calculate overall accuracy by taking the mean of the lists
overall_training_accuracy = np.mean(acc1)
overall_validation_accuracy = np.mean(acc2)

# Calculate total overall accuracy as the average of training and validation accuracy
overall_accuracy = (overall_training_accuracy + overall_validation_accuracy) / 2

# Printing the overall accuracy
print("Overall training accuracy:", overall_training_accuracy)
print("Overall validation accuracy:", overall_validation_accuracy)
print("Overall accuracy of the model:", overall_accuracy)

"""Our model achieved **43.6% training accuracy** and **38.9% validation accuracy**, resulting in an **overall accuracy of 41.3%**. While the model is learning, the gap between training and validation accuracy suggests some generalization issues. To improve performance, we can try further tuning, enhanced data augmentation, or experimenting with different architectures. We're on the right trackâ€”let's keep optimizing! ðŸš€"""

